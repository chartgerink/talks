Where's the evidence?
========================================================
author: Chris Hartgerink
date: October 5, 2016
autosize: true

Disclosure
========================================================

- I am a statistician
- I understood nothing of your abstracts
- Yet I am here to tell you about evidence
- Let's hope this doesn't get awkward.


Statistics, statistics --- more statistics?
========================================================

<!--translate data into meaning-->

- Language game 
- $p<.05$ truth! 
- $p>.05$ failure!
- Legitimacy through "objective" numbers
- But all results are a matter of choices

What statistics?
========================================================

![letsplay](imgs/saw)

*** 
*P*-values are:

- [A] the probability that an effect will replicate
- [B] the probability that the null hypothesis is true
- [C] the probability of more extreme data under the null hypothesis
- [D] the probability of finding an effect
- [E] none of the above

What statistics?
========================================================

![letsplay](imgs/saw)

*** 
*P*-values are:

- [A] the probability that an effect will replicate
- [B] the probability that the null hypothesis is true
- **[C] the probability of more extreme data under the null hypothesis**
- [D] the probability of finding an effect
- [E] none of the above

What statistics?
========================================================
title:false

- *P*-values are the probability of the data, given the null hypothesis
- If unlikely, reject the null.
- Nonsignificant does not PROVE the null is true
- After all: $p(D|H_0)\neq p(H_0|D)$

Results of misinterpretation of results
========================================================

- Publication bias
- Prettified results sections
- Hot, unlikely hypotheses
- Reproducibility problems

Too good to be true
========================================================

![letsplay](imgs/saw)

Too good to be true
========================================================

Which sequence of results is the most convincing for an effect, if both the null and alternative hypotheses are equally likely and the studies are well powered?

***

- [A] 1 significant, 3 nonsignificant
- [B] 2 significant, 2 nonsignificant
- [C] 3 significant, 1 nonsignificant
- [D] 4 significant, 0 nonsignificant

Too good to be true
========================================================

Which sequence of results is the most convincing for an effect, if both the null and alternative hypotheses are equally likely and the studies are well powered?

***

- [A] 1 significant, 3 nonsignificant
- [B] 2 significant, 2 nonsignificant
- [C] 3 significant, 1 nonsignificant
- **[D] 4 significant, 0 nonsignificant**

```{r echo = FALSE}
beta <- .2
h1 <- .1
h0 <- 1 - h1
N <- 4
k <- 1:4
alpha <- .05

x <- ((1 - beta)^k * beta^(N-k) * h1) /
  (((1 - beta)^k * beta^(N-k) * h1) + (alpha^k * (1 - alpha)^(N-k)) * h0)
```

Too good to be true
========================================================

Which sequence of results is the most convincing for an effect, if both the null and alternative hypotheses are equally likely and the studies are well powered?

***

- [A] 1 significant, 3 nonsignificant; $P(H_1|D)=`r round(x[1], 3)`$
- [B] 2 significant, 2 nonsignificant; $P(H_1|D)=`r round(x[2], 3)`$
- **[C] 3 significant, 1 nonsignificant; $P(H_1|D)=`r round(x[3], 3)`$**
- **[D] 4 significant, 0 nonsignificant; $P(H_1|D)=`r round(x[4], 3)`$**

Too good to be false
========================================================

- Nonsignificant effects abound
- "What went wrong?"
- Nonsense!
- Failure is based on methods, not results

Too good to be false
========================================================
title:false

```{r echo=FALSE, eval = TRUE}
library(stringr)
pvals <- read.csv('pvals.csv', header = FALSE)
sel <- grepl(pvals[ ,1], pattern = '=')

x <- pvals[sel,1] %>% 
  str_match_all(pattern = '\\d?\\.\\d*') %>%
  unlist %>%
  as.numeric
```

- Recognize these?
- `r x`

***


Too good to be false
========================================================
title:false

```{r echo=FALSE, eval = TRUE}
library(stringr)
pvals <- read.csv('pvals.csv', header = FALSE)
sel <- grepl(pvals[ ,1], pattern = '=')

x <- pvals[sel,1] %>% 
  str_match_all(pattern = '\\d?\\.\\d*') %>%
  unlist %>%
  as.numeric
```

- Recognize these?
- `r x`

***

- *P*-values from the abstracts presented here
- Let us look for false negatives!

Too good to be false
========================================================
title:false

- Test for evidence of an effect in just the nonsignificant results
- How? 
- $\chi^2_k=-2\sum\limits^k_{i=1}ln(\frac{p_i-\alpha}{1-\alpha})$
- In words: are the *p*-values uniformly distributed?
- If not: $\geq1$ false negatives!

Too good to be false
========================================================
title:false

```{r echo = FALSE}
chi <- -2*sum(log((x[x > .05] - .05) / (1 - .05)))
df <- 2*length(x[x > .05])
```
- 7 nonsignificant results
- $\chi^2(`r df`)=`r round(chi, 2)`$, $p=`r round(pchisq(chi, df, lower.tail = FALSE), 2)`$
- Evidence for $\geq1$ false negative in the results presented here


Take home
========================================================

- Don't judge your results on the results
- Judge the results on the methodology

Take home
========================================================

- Don't judge your results on the results
- Judge the results on the methodology
- With great statistics, comes great responsibility

Take home
========================================================

- Don't judge your results on the results
- Judge the results on the methodology
- With great statistics, comes great responsibility

# chjh.nl/debs

# chjh@protonmail.com

# @chartgerink

Grand finale
========================================================

![letsplay](imgs/saw)

*** 

Under publication bias, a *p*-value between .025-.05 is more likely under the null hypothesis than under the alternative hypothesis. 

- [A] Yes
- [B] No

Grand finale
========================================================

![letsplay](imgs/saw)

*** 

Under publication bias, a *p*-value between .025-.05 is more likely under the null hypothesis than under the alternative hypothesis. 

- **[A] Yes**
- [B] No
